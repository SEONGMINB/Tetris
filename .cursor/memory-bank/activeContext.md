# 활성 컨텍스트 (Active Context)

## 🎯 현재 작업 상태

### 최근 완료된 작업
1. **강화학습 AI 훈련 완료** (방금 전)
   - 50 에피소드 Q-Learning 훈련 실행
   - 33개 게임 상태 학습
   - 탐험률 0.27 → 0.21로 감소 (학습 진행)
   - 모델이 `tetris_q_model.json`에 저장됨

2. **메모리 뱅크 시스템 초기화** (현재)
   - 프로젝트 기본 문서화 구조 생성
   - 핵심 6개 파일 생성 중

### 현재 진행 중인 작업
- **메모리 뱅크 문서 생성**: `activeContext.md`, `progress.md` 생성 필요
- **AI 실행 대기**: 학습된 모델로 플레이 모드 실행 준비 상태

## 🔄 다음 단계

### 즉시 실행 가능한 작업
1. **학습된 AI 플레이**: 방금 훈련한 모델로 실제 게임 플레이
2. **메모리 뱅크 완성**: `progress.md` 파일 생성으로 문서화 완료

### 단기 개선 과제
- AI 성능 평가 및 추가 훈련
- 더 긴 시간 플레이 테스트
- 다른 AI 알고리즘과 성능 비교

## 🚨 현재 이슈 및 제약사항

### 발견된 패턴
- **게임 오버 빈발**: 훈련 중 대부분 에피소드가 즉시 게임 오버
- **상태 공간 제한**: 33개 상태만 학습됨 (확장 필요)
- **탐험 vs 활용**: 탐험률이 여전히 높아 더 많은 훈련 필요

### 기술적 제약
- HTTP 폴링 기반 통신 (200ms 간격)
- JSON 기반 Q-table 저장 (메모리 효율성 제한)
- 브라우저-Python 간 수동 동기화 필요

## 🎮 사용자 상호작용 패턴

### 언어 설정
- **주 언어**: 한국어 (사용자 설정)
- **코드 주석**: 한국어 포함
- **출력 형식**: 이모지 + 한국어 설명

### 실행 환경 패턴
- **서버 관리**: 사용자가 직접 실행 (pnpm, npm, next 등)
- **AI 실행**: 개발자가 Python 스크립트 실행
- **협업 방식**: 명령 제안 → 사용자 승인 → 실행

## 📝 활성 결정사항

### 현재 세션에서 확정된 사항
1. **AI 훈련 방식**: Q-Learning 기반 강화학습
2. **문서화 구조**: Cursor Memory Bank 패턴 채택
3. **개발 언어**: 한국어 기반 소통

### 보류 중인 결정사항
- AI 추가 훈련 여부 (더 많은 에피소드)
- 다른 AI 알고리즘 테스트 여부
- 성능 개선 방향성

## 🔍 모니터링 중인 지표

### AI 학습 성과
- **학습된 상태 수**: 33개 (목표: 100+ 상태)
- **탐험률**: 0.211 (목표: 0.1 이하)
- **평균 생존 시간**: 매우 짧음 (개선 필요)

### 시스템 성능
- **API 응답 시간**: 정상 (200ms 폴링)
- **게임 상태 동기화**: 안정적
- **모델 저장/로드**: 정상 작동

## 🎯 세션 목표

### 이번 세션에서 달성하고자 하는 것
1. ✅ AI 강화학습 훈련 실행
2. ✅ 메모리 뱅크 시스템 구축 (진행 중)
3. ⏳ 학습된 AI 플레이 시연
4. ⏳ AI 성능 평가 및 개선 방향 논의

### 성공 기준
- AI가 최소 30초 이상 게임 플레이 지속
- 이전보다 향상된 점수 달성
- 안정적인 웹-AI 통신 확인

## 🚀 확장 가능성

### 즉시 시도 가능한 개선사항
- 더 많은 에피소드로 추가 훈련
- 휴리스틱 AI와 성능 비교
- 다양한 하이퍼파라미터 실험

### 향후 개발 방향
- 딥러닝 기반 AI (DQN, PPO) 구현
- 실시간 학습 시각화
- 멀티 에이전트 시스템 