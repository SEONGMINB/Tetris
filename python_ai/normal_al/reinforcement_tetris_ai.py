#!/usr/bin/env python3
"""
ê°•í™”í•™ìŠµ ê¸°ë°˜ í…ŒíŠ¸ë¦¬ìŠ¤ AI
Deep Q-Network (DQN) ì‚¬ìš©
"""
import requests
import time
import numpy as np
import random
from collections import deque
import json
import os

# TensorFlow/PyTorchê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ Q-learning êµ¬í˜„
class QLearningAgent:
    def __init__(self, state_size=200, action_size=6, learning_rate=0.1, discount_factor=0.95, epsilon=1.0):
        self.state_size = state_size  # 20x10 ë³´ë“œ
        self.action_size = action_size  # left, right, down, rotate, drop
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon  # exploration rate
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        
        # Q-table ì´ˆê¸°í™” (ì‹¤ì œë¡œëŠ” ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©)
        self.q_table = {}
        self.memory = deque(maxlen=2000)
        
        # ì•¡ì…˜ ë§¤í•‘
        self.actions = ['left', 'right', 'down', 'rotate', 'drop', 'restart']
        
    def state_to_key(self, state):
        """ê²Œì„ ìƒíƒœë¥¼ Q-table í‚¤ë¡œ ë³€í™˜"""
        if not state or 'board' not in state:
            return "empty"
        
        board = state['board']
        # ë³´ë“œë¥¼ ê°„ë‹¨í•œ íŠ¹ì§•ìœ¼ë¡œ ë³€í™˜
        features = []
        
        # 1. ê° ì—´ì˜ ë†’ì´
        heights = []
        for col in range(10):
            height = 0
            for row in range(20):
                if board[row][col] is not None and board[row][col] != 0:
                    height = 20 - row
                    break
            heights.append(min(height, 10))  # ìµœëŒ€ 10ìœ¼ë¡œ ì œí•œ
        
        # 2. êµ¬ë© ê°œìˆ˜ (ê°„ë‹¨í™”)
        holes = 0
        for col in range(10):
            block_found = False
            for row in range(20):
                if board[row][col] is not None and board[row][col] != 0:
                    block_found = True
                elif block_found and (board[row][col] is None or board[row][col] == 0):
                    holes += 1
        holes = min(holes, 20)  # ìµœëŒ€ 20ìœ¼ë¡œ ì œí•œ
        
        # 3. ì™„ì„± ê°€ëŠ¥í•œ ë¼ì¸
        complete_lines = 0
        for row in range(20):
            filled_cells = sum(1 for cell in board[row] if cell is not None and cell != 0)
            if filled_cells >= 8:  # ê±°ì˜ ì™„ì„±ëœ ë¼ì¸
                complete_lines += 1
        
        # íŠ¹ì§•ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (í•´ì‹œ í‚¤ë¡œ ì‚¬ìš©)
        key = f"h:{'-'.join(map(str, heights[:5]))}|holes:{holes}|lines:{complete_lines}"
        return key
    
    def get_action(self, state):
        """í˜„ì¬ ìƒíƒœì—ì„œ ì•¡ì…˜ ì„ íƒ (Îµ-greedy)"""
        if np.random.random() <= self.epsilon:
            # íƒí—˜: ëœë¤ ì•¡ì…˜
            return random.choice(range(self.action_size))
        
        # í™œìš©: Q-ê°’ì´ ê°€ì¥ ë†’ì€ ì•¡ì…˜
        state_key = self.state_to_key(state)
        if state_key not in self.q_table:
            self.q_table[state_key] = [0.0] * self.action_size
        
        return np.argmax(self.q_table[state_key])
    
    def remember(self, state, action, reward, next_state, done):
        """ê²½í—˜ì„ ë©”ëª¨ë¦¬ì— ì €ì¥"""
        self.memory.append((state, action, reward, next_state, done))
    
    def calculate_reward(self, prev_state, current_state):
        """ë³´ìƒ ê³„ì‚°"""
        if not prev_state or not current_state:
            return 0
        
        reward = 0
        
        # ì ìˆ˜ ì¦ê°€ ë³´ìƒ
        score_diff = current_state.get('score', 0) - prev_state.get('score', 0)
        reward += score_diff * 0.01
        
        # ë¼ì¸ í´ë¦¬ì–´ ë³´ìƒ
        lines_diff = current_state.get('lines', 0) - prev_state.get('lines', 0)
        reward += lines_diff * 10
        
        # ê²Œì„ ì˜¤ë²„ íŒ¨ë„í‹°
        if current_state.get('isGameOver', False):
            reward -= 50
        
        # ë†’ì´ íŒ¨ë„í‹°
        if current_state.get('board'):
            board = current_state['board']
            max_height = 0
            for col in range(10):
                for row in range(20):
                    if board[row][col] is not None and board[row][col] != 0:
                        max_height = max(max_height, 20 - row)
                        break
            
            if max_height > 15:
                reward -= (max_height - 15) * 2
        
        return reward
    
    def replay(self, batch_size=32):
        """ê²½í—˜ ì¬ìƒì„ í†µí•œ í•™ìŠµ"""
        if len(self.memory) < batch_size:
            return
        
        batch = random.sample(self.memory, batch_size)
        
        for state, action, reward, next_state, done in batch:
            state_key = self.state_to_key(state)
            next_state_key = self.state_to_key(next_state)
            
            # Q-table ì´ˆê¸°í™”
            if state_key not in self.q_table:
                self.q_table[state_key] = [0.0] * self.action_size
            if next_state_key not in self.q_table:
                self.q_table[next_state_key] = [0.0] * self.action_size
            
            # Q-learning ì—…ë°ì´íŠ¸
            target = reward
            if not done:
                target += self.discount_factor * max(self.q_table[next_state_key])
            
            # Q-ê°’ ì—…ë°ì´íŠ¸
            self.q_table[state_key][action] += self.learning_rate * (target - self.q_table[state_key][action])
        
        # epsilon ê°ì†Œ (íƒí—˜ -> í™œìš©)
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay
    
    def save_model(self, filepath):
        """Q-table ì €ì¥"""
        model_data = {
            'q_table': self.q_table,
            'epsilon': self.epsilon
        }
        with open(filepath, 'w') as f:
            json.dump(model_data, f, indent=2)
    
    def load_model(self, filepath):
        """Q-table ë¡œë“œ"""
        if os.path.exists(filepath):
            with open(filepath, 'r') as f:
                model_data = json.load(f)
                self.q_table = model_data.get('q_table', {})
                self.epsilon = model_data.get('epsilon', self.epsilon)
            print(f"âœ… ëª¨ë¸ ë¡œë“œë¨: {len(self.q_table)}ê°œ ìƒíƒœ")
        else:
            print("âŒ ì €ì¥ëœ ëª¨ë¸ ì—†ìŒ, ìƒˆë¡œ í•™ìŠµ ì‹œì‘")

class TetrisAPIClient:
    def __init__(self, base_url="http://localhost:3000"):
        self.base_url = base_url
        self.api_url = f"{base_url}/api/game"
    
    def get_game_state(self):
        try:
            response = requests.get(self.api_url, timeout=5)
            if response.status_code == 200:
                data = response.json()
                return data.get('data', {})
        except:
            pass
        return None
    
    def send_action(self, action):
        try:
            response = requests.post(self.api_url, json={
                'type': 'action', 
                'action': action
            }, timeout=5)
            return response.status_code == 200
        except:
            return False

class ReinforcementTetrisAI:
    def __init__(self):
        self.agent = QLearningAgent()
        self.client = TetrisAPIClient()
        self.model_path = "tetris_q_model.json"
        
        # ëª¨ë¸ ë¡œë“œ
        self.agent.load_model(self.model_path)
    
    def train(self, episodes=100, max_steps=1000):
        """ê°•í™”í•™ìŠµ í›ˆë ¨"""
        print("ğŸ§  ê°•í™”í•™ìŠµ í›ˆë ¨ ì‹œì‘!")
        print(f"ğŸ“Š ì—í”¼ì†Œë“œ: {episodes}, ìµœëŒ€ ìŠ¤í…: {max_steps}")
        print("=" * 50)
        
        for episode in range(episodes):
            print(f"\nğŸ® ì—í”¼ì†Œë“œ {episode + 1}/{episodes}")
            
            # ê²Œì„ ìƒíƒœ ì´ˆê¸°í™”
            prev_state = self.client.get_game_state()
            if not prev_state:
                print("âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
                continue
            
            total_reward = 0
            step = 0
            
            for step in range(max_steps):
                # í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                current_state = self.client.get_game_state()
                if not current_state:
                    break
                
                # ê²Œì„ ì˜¤ë²„ ì²´í¬
                if current_state.get('isGameOver', False):
                    print(f"   ğŸ’€ ê²Œì„ ì˜¤ë²„! ìŠ¤í…: {step} - ìë™ ì¬ì‹œì‘...")
                    # ìë™ìœ¼ë¡œ ì¬ì‹œì‘ ì•¡ì…˜ ì „ì†¡
                    if self.client.send_action('restart'):
                        print(f"   ğŸ”„ ê²Œì„ ì¬ì‹œì‘ë¨")
                        time.sleep(1)  # ì¬ì‹œì‘ í›„ ì ì‹œ ëŒ€ê¸°
                        continue  # ì—í”¼ì†Œë“œ ê³„ì† ì§„í–‰
                    else:
                        print(f"   âŒ ì¬ì‹œì‘ ì‹¤íŒ¨")
                        break
                
                # ì•¡ì…˜ ì„ íƒ
                action_idx = self.agent.get_action(current_state)
                action = self.agent.actions[action_idx]
                
                # ì•¡ì…˜ ì‹¤í–‰
                if not self.client.send_action(action):
                    continue
                
                time.sleep(0.3)  # ì•¡ì…˜ ê°„ê²© (ë” ì•ˆì •ì )
                
                # ë‹¤ìŒ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
                next_state = self.client.get_game_state()
                if not next_state:
                    continue
                
                # ë³´ìƒ ê³„ì‚°
                reward = self.agent.calculate_reward(current_state, next_state)
                total_reward += reward
                
                # ê²½í—˜ ì €ì¥
                done = next_state.get('isGameOver', False)
                self.agent.remember(current_state, action_idx, reward, next_state, done)
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if step % 50 == 0:
                    score = next_state.get('score', 0)
                    lines = next_state.get('lines', 0)
                    print(f"   ğŸ“ˆ ìŠ¤í… {step}: ì ìˆ˜ {score}, ë¼ì¸ {lines}, ë³´ìƒ {reward:.2f}")
                
                prev_state = current_state
                
                if done:
                    break
            
            # í•™ìŠµ ìˆ˜í–‰
            self.agent.replay()
            
            # ì—í”¼ì†Œë“œ ê²°ê³¼ ì¶œë ¥
            final_score = current_state.get('score', 0) if current_state else 0
            final_lines = current_state.get('lines', 0) if current_state else 0
            
            print(f"   ğŸ¯ ì—í”¼ì†Œë“œ ì™„ë£Œ!")
            print(f"   ğŸ“Š ìµœì¢… ì ìˆ˜: {final_score}, ë¼ì¸: {final_lines}")
            print(f"   ğŸ ì´ ë³´ìƒ: {total_reward:.2f}")
            print(f"   ğŸ” íƒí—˜ë¥ : {self.agent.epsilon:.3f}")
            print(f"   ğŸ§  í•™ìŠµëœ ìƒíƒœ: {len(self.agent.q_table)}")
            
            # ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë¸ ì €ì¥
            if (episode + 1) % 10 == 0:
                self.agent.save_model(self.model_path)
                print(f"   ğŸ’¾ ëª¨ë¸ ì €ì¥ë¨ (ì—í”¼ì†Œë“œ {episode + 1})")
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        self.agent.save_model(self.model_path)
        print(f"\nâœ… í›ˆë ¨ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ë¨: {self.model_path}")
    
    def play(self, duration=120):
        """í•™ìŠµëœ AIë¡œ í”Œë ˆì´"""
        print("ğŸ¤– í•™ìŠµëœ AIê°€ í”Œë ˆì´í•©ë‹ˆë‹¤!")
        print(f"ğŸ• í”Œë ˆì´ ì‹œê°„: {duration}ì´ˆ")
        print(f"ğŸ” íƒí—˜ë¥ : {self.agent.epsilon:.3f}")
        print("=" * 40)
        
        start_time = time.time()
        step = 0
        
        while time.time() - start_time < duration:
            state = self.client.get_game_state()
            if not state:
                time.sleep(0.5)
                continue
            
            if state.get('isGameOver', False):
                print(f"ğŸ¯ ê²Œì„ ì˜¤ë²„! ì ìˆ˜: {state.get('score', 0)} - ìë™ ì¬ì‹œì‘...")
                # ìë™ìœ¼ë¡œ ì¬ì‹œì‘ ì•¡ì…˜ ì „ì†¡
                if self.client.send_action('restart'):
                    print(f"ğŸ”„ ê²Œì„ ì¬ì‹œì‘ë¨, ê³„ì† í”Œë ˆì´...")
                    time.sleep(1)  # ì¬ì‹œì‘ í›„ ì ì‹œ ëŒ€ê¸°
                    continue  # í”Œë ˆì´ ê³„ì† ì§„í–‰
                else:
                    print(f"âŒ ì¬ì‹œì‘ ì‹¤íŒ¨")
                    break
            
            # ìµœì  ì•¡ì…˜ ì„ íƒ (íƒí—˜ ì—†ì´)
            old_epsilon = self.agent.epsilon
            self.agent.epsilon = 0  # ìˆœìˆ˜ í™œìš© ëª¨ë“œ
            
            action_idx = self.agent.get_action(state)
            action = self.agent.actions[action_idx]
            
            self.agent.epsilon = old_epsilon
            
            # ì•¡ì…˜ ì‹¤í–‰
            if self.client.send_action(action):
                step += 1
                if step % 20 == 0:
                    score = state.get('score', 0)
                    lines = state.get('lines', 0)
                    print(f"ğŸ® ìŠ¤í… {step}: ì ìˆ˜ {score}, ë¼ì¸ {lines}, ì•¡ì…˜ {action}")
            
            time.sleep(0.4)  # í”Œë ˆì´ ëª¨ë“œì—ì„œ ë” ì•ˆì •ì ì¸ ê°„ê²©
        
        print(f"âœ… í”Œë ˆì´ ì™„ë£Œ! ì´ {step} ì•¡ì…˜")

def main():
    print("ğŸ§  ê°•í™”í•™ìŠµ í…ŒíŠ¸ë¦¬ìŠ¤ AI")
    print("=" * 40)
    
    ai = ReinforcementTetrisAI()
    
    # ì„œë²„ ì—°ê²° í™•ì¸
    if not ai.client.get_game_state():
        print("âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ 'pnpm dev'ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•˜ê³  ë¸Œë¼ìš°ì €ì—ì„œ 'AI ëª¨ë“œ ON'ì„ í´ë¦­í•˜ì„¸ìš”.")
        return
    
    mode = input("\nëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:\n1. í›ˆë ¨ (train)\n2. í”Œë ˆì´ (play)\nì„ íƒ (1 ë˜ëŠ” 2): ")
    
    if mode == "1":
        episodes = int(input("í›ˆë ¨ ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸ 50): ") or "50")
        ai.train(episodes=episodes)
    elif mode == "2":
        duration = int(input("í”Œë ˆì´ ì‹œê°„(ì´ˆ) (ê¸°ë³¸ 120): ") or "120")
        ai.play(duration=duration)
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 